{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Task List 6 - Bayes classifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics as mtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\"\n",
    "    columns = ['Price', 'Maintenance', 'Doors', 'Persons', 'Luggage_boot', 'Safety', 'Class']\n",
    "    return pd.read_csv(url, header=None, names=columns)\n",
    "\n",
    "\n",
    "def calc_attr_probs(ds, attr_name):\n",
    "    attr_counts = dict(dataset.groupby(attr_name).size())\n",
    "    return {k: v / ds.shape[0] for k, v in attr_counts.items()}\n",
    "\n",
    "\n",
    "def calc_attr_prob_when_class(ds, attribute_name, attribute_value, class_name):\n",
    "    ds_attr_and_class = ds[(ds['Class'] == class_name) & (ds[attribute_name] == attribute_value)]\n",
    "    ds_class = ds[ds['Class'] == class_name]\n",
    "    return ds_attr_and_class.shape[0] / ds_class.shape[0]\n",
    "\n",
    "\n",
    "def calc_all_probs(ds, attribute_names):\n",
    "    probs = {}\n",
    "    classes = list(set(ds['Class']))\n",
    "    \n",
    "    for attr_name in attribute_names:\n",
    "        attr_vals = list(set(ds[attr_name]))\n",
    "        for attr_val in attr_vals:\n",
    "            for cls in classes:\n",
    "                probs[(attr_name, attr_val, cls)] = calc_attr_prob_when_class(ds, attr_name, attr_val, cls)\n",
    "                \n",
    "    return probs\n",
    "\n",
    "\n",
    "def make_instance(x):\n",
    "    return {'Price': x[0], \n",
    "            'Maintenance': x[1], \n",
    "            'Doors': x[2],\n",
    "            'Persons': x[3],\n",
    "            'Luggage_boot': x[4], \n",
    "            'Safety': x[5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class BayesClassfier(object):\n",
    "    def __init__(self):\n",
    "        self.probs = None\n",
    "        self.class_probs = None\n",
    "    \n",
    "    def fit(self, ds):\n",
    "        attributes = list(dataset.columns.values)\n",
    "        attributes.remove('Class')\n",
    "        \n",
    "        self.probs = calc_all_probs(ds, attributes)\n",
    "        self.class_probs = calc_attr_probs(ds, 'Class')\n",
    "    \n",
    "    def predict(self, x):\n",
    "        best_posterior = -1\n",
    "        best_class = None\n",
    "        \n",
    "        instance = make_instance(x)\n",
    "        classes = list(self.class_probs.keys())\n",
    "        evidence = self._calc_evidence(instance)\n",
    "        \n",
    "        for cls_name in classes:\n",
    "            likelihood = self._calc_likelihood(instance, cls_name)\n",
    "            prior = self.class_probs[cls_name]\n",
    "            posterior = likelihood * prior / evidence\n",
    "            \n",
    "            if posterior > best_posterior:\n",
    "                best_posterior = posterior\n",
    "                best_class = cls_name\n",
    "                \n",
    "        return best_class, best_posterior\n",
    "            \n",
    "    def _calc_likelihood(self, instance, cls_name):\n",
    "        likelihood = 1\n",
    "        for attr_name, attr_val in instance.items():\n",
    "            likelihood *= self.probs[(attr_name, attr_val, cls_name)]\n",
    "        return likelihood\n",
    "    \n",
    "    def _calc_evidence(self, instance):\n",
    "        classes = list(self.class_probs.keys())\n",
    "        evidence = 0\n",
    "        \n",
    "        for cls_name in classes:\n",
    "            evidence += self._calc_likelihood(instance, cls_name) * self.class_probs[cls_name]\n",
    "            \n",
    "        return evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Separate cell cause of loading time ...\n",
    "dataset = load_dataset()\n",
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vhigh', 'vhigh', '2', '2', 'small', 'low'] => ('unacc', 1.0)\n"
     ]
    }
   ],
   "source": [
    "def example_test():\n",
    "    bc = BayesClassfier()\n",
    "\n",
    "    bc.fit(dataset)\n",
    "\n",
    "    x = ['vhigh', 'vhigh', '2', '2', 'small', 'low']\n",
    "    y_pred = bc.predict(x)\n",
    "\n",
    "    print(x, '=>', y_pred)\n",
    "    \n",
    "example_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluate_classifier_own(train_ds, test_ds):\n",
    "    bc = BayesClassfier()\n",
    "    bc.fit(train_ds)\n",
    "    \n",
    "    y_true = test_ds['Class'].tolist()\n",
    "    y_pred = [bc.predict(x.tolist())[0] for _, x in test_ds.iterrows()]\n",
    "    \n",
    "    cnf_matrix = mtr.confusion_matrix(y_true, y_pred)\n",
    "    accuracy = mtr.accuracy_score(y_true, y_pred) * 100.0\n",
    "    precision = mtr.precision_score(y_true, y_pred, average='macro') * 100.0\n",
    "    recall = mtr.recall_score(y_true, y_pred, average='macro') * 100.0\n",
    "    f1 = mtr.f1_score(y_true, y_pred, average='macro') * 100.0\n",
    "    \n",
    "    print(\"---- Confusion matrix ----\")\n",
    "    print(cnf_matrix)\n",
    "    print('Accuracy: %.2f' % accuracy)\n",
    "    print('Precision: %.2f' % precision)\n",
    "    print('Recall: %.2f' % recall)\n",
    "    print('F1: %.2f' % f1)\n",
    "    \n",
    "    # Accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "    # Precision = TP / (TP + FP)\n",
    "    # Recall = TP / (TP + FN)\n",
    "    # F1 =  2 * precision * recall / (precision + recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "def preprocess(ds):\n",
    "    ds_cpy = deepcopy(ds)\n",
    "    \n",
    "    ds_cpy['Price'] = ds_cpy['Price'].map({'low': 0, 'med': 1, 'high': 2, 'vhigh': 3})\n",
    "    ds_cpy['Maintenance'] = ds_cpy['Maintenance'].map({'low': 0, 'med': 1, 'high': 2, 'vhigh': 3})\n",
    "    ds_cpy['Doors'] = ds_cpy['Doors'].map({'2': 2, '3': 3, '4': 4, '5more': 5})\n",
    "    ds_cpy['Persons'] = ds_cpy['Persons'].map({'2': 2, '4': 4, 'more': 5})\n",
    "    ds_cpy['Luggage_boot'] = ds_cpy['Luggage_boot'].map({'small': 0, 'med': 1, 'big': 2})\n",
    "    ds_cpy['Safety'] = ds_cpy['Safety'].map({'low': 0, 'med': 1, 'high': 2})\n",
    "    ds_cpy['Class'] = ds_cpy['Class'].map({'unacc': 0, 'acc': 1, 'good': 2, 'vgood': 3})\n",
    "    \n",
    "    return ds_cpy\n",
    "\n",
    "\n",
    "def evaluate_classifier_sklearn(train_ds, test_ds):\n",
    "    bc = MultinomialNB(fit_prior=False)\n",
    "    \n",
    "    train_ds_cpy = preprocess(train_ds)\n",
    "    test_ds_cpy = preprocess(test_ds)\n",
    "    \n",
    "    train_X = train_ds_cpy[['Price', 'Maintenance', 'Doors', 'Persons', 'Luggage_boot', 'Safety']]\n",
    "    train_Y = train_ds_cpy['Class']\n",
    "    \n",
    "    bc.fit(train_X, train_Y)\n",
    "    \n",
    "    test_X = test_ds_cpy[['Price', 'Maintenance', 'Doors', 'Persons', 'Luggage_boot', 'Safety']]\n",
    "    \n",
    "    y_true = test_ds_cpy['Class']\n",
    "    y_pred = bc.predict(test_X)\n",
    "    #y_pred = cross_val_predict(bc, test_X, y_true, cv=8)\n",
    "    \n",
    "    cnf_matrix = mtr.confusion_matrix(y_true, y_pred)\n",
    "    accuracy = mtr.accuracy_score(y_true, y_pred) * 100.0\n",
    "    precision = mtr.precision_score(y_true, y_pred, average='macro') * 100.0\n",
    "    recall = mtr.recall_score(y_true, y_pred, average='macro') * 100.0\n",
    "    f1 = mtr.f1_score(y_true, y_pred, average='macro') * 100.0\n",
    "    \n",
    "    print(\"---- Confusion matrix ----\")\n",
    "    print(cnf_matrix)\n",
    "    print('Accuracy: %.2f' % accuracy)\n",
    "    print('Precision: %.2f' % precision)\n",
    "    print('Recall: %.2f' % recall)\n",
    "    print('F1: %.2f' % f1)\n",
    "    \n",
    "    print('Log_class_prior:', bc.class_log_prior_)\n",
    "    print('Feature_count:', bc.feature_count_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Own:\n",
      "---- Confusion matrix ----\n",
      "[[ 64   1  20   0]\n",
      " [ 11   6   0   1]\n",
      " [ 11   0 222   0]\n",
      " [  3   0   0   7]]\n",
      "Accuracy: 86.42\n",
      "Precision: 84.21\n",
      "Recall: 68.48\n",
      "F1: 73.20\n",
      "\n",
      "\n",
      "Sklearn:\n",
      "---- Confusion matrix ----\n",
      "[[150  44  21  18]\n",
      " [ 12  60   3  10]\n",
      " [  0   0  13   5]\n",
      " [  0   0   4   6]]\n",
      "Accuracy: 66.18\n",
      "Precision: 49.34\n",
      "Recall: 66.80\n",
      "F1: 52.00\n",
      "Log_class_prior: [-1.38629436 -1.38629436 -1.38629436 -1.38629436]\n",
      "Feature_count: [[1623. 1596. 3383. 3267.  916.  719.]\n",
      " [ 422.  411. 1067. 1344.  325.  452.]\n",
      " [  17.   17.  182.  227.   49.   75.]\n",
      " [  22.   44.  203.  251.   87.  110.]]\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds = train_test_split(dataset, test_size=0.2)\n",
    "\n",
    "\n",
    "print('Own:')\n",
    "evaluate_classifier_own(train_ds, test_ds)\n",
    "\n",
    "print('\\n\\nSklearn:')\n",
    "evaluate_classifier_sklearn(train_ds, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.2222222222222222, 'good': 0.03993055555555555, 'unacc': 0.7002314814814815, 'vgood': 0.03761574074074074}\n"
     ]
    }
   ],
   "source": [
    "print(calc_attr_probs(dataset, 'Class'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
