{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Task List 6 - Bayes classifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics as mtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/car/car.data\"\n",
    "    columns = ['Price', 'Maintenance', 'Doors', 'Persons', 'Luggage_boot', 'Safety', 'Class']\n",
    "    return pd.read_csv(url, header=None, names=columns)\n",
    "\n",
    "\n",
    "def calc_attr_probs(ds, attr_name):\n",
    "    attr_counts = dict(dataset.groupby(attr_name).size())\n",
    "    return {k: v / ds.shape[0] for k, v in attr_counts.items()}\n",
    "\n",
    "\n",
    "def calc_attr_prob_when_class(ds, attribute_name, attribute_value, class_name):\n",
    "    ds_attr_and_class = ds[(ds['Class'] == class_name) & (ds[attribute_name] == attribute_value)]\n",
    "    ds_class = ds[ds['Class'] == class_name]\n",
    "    return ds_attr_and_class.shape[0] / ds_class.shape[0]\n",
    "\n",
    "\n",
    "def calc_all_probs(ds, attribute_names):\n",
    "    probs = {}\n",
    "    classes = list(set(ds['Class']))\n",
    "    \n",
    "    for attr_name in attribute_names:\n",
    "        attr_vals = list(set(ds[attr_name]))\n",
    "        for attr_val in attr_vals:\n",
    "            for cls in classes:\n",
    "                probs[(attr_name, attr_val, cls)] = calc_attr_prob_when_class(ds, attr_name, attr_val, cls)\n",
    "                \n",
    "    return probs\n",
    "\n",
    "\n",
    "def make_instance(x):\n",
    "    return {'Price': x[0], \n",
    "            'Maintenance': x[1], \n",
    "            'Doors': x[2],\n",
    "            'Persons': x[3],\n",
    "            'Luggage_boot': x[4], \n",
    "            'Safety': x[5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class BayesClassfier(object):\n",
    "    def __init__(self):\n",
    "        self.probs = None\n",
    "        self.class_probs = None\n",
    "        self.attr_probs = {}\n",
    "    \n",
    "    def fit(self, ds):\n",
    "        attributes = list(dataset.columns.values)\n",
    "        attributes.remove('Class')\n",
    "        \n",
    "        self.probs = calc_all_probs(ds, attributes)\n",
    "        self.class_probs = calc_attr_probs(ds, 'Class')\n",
    "        for attr in attributes:\n",
    "            self.attr_probs[attr] = calc_attr_probs(ds, attr)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        best_posterior = -1\n",
    "        best_class = None\n",
    "        \n",
    "        instance = make_instance(x)\n",
    "        classes = list(self.class_probs.keys())\n",
    "        evidence = self._calc_evidence(instance)\n",
    "        \n",
    "        for cls_name in classes:\n",
    "            likelihood = self._calc_likelihood(instance, cls_name)\n",
    "            prior = self.class_probs[cls_name]\n",
    "            posterior = likelihood * prior / evidence\n",
    "            \n",
    "            if posterior > best_posterior:\n",
    "                best_posterior = posterior\n",
    "                best_class = cls_name\n",
    "                \n",
    "        return best_class, best_posterior\n",
    "            \n",
    "    def _calc_likelihood(self, instance, cls_name):\n",
    "        likelihood = 1\n",
    "        for attr_name, attr_val in instance.items():\n",
    "            likelihood *= self.probs[(attr_name, attr_val, cls_name)]\n",
    "        return likelihood\n",
    "    \n",
    "    def _calc_evidence(self, instance):\n",
    "        classes = list(self.class_probs.keys())\n",
    "        evidence = 0\n",
    "        \n",
    "        for cls_name in classes:\n",
    "            evidence += self._calc_likelihood(instance, cls_name) * self.class_probs[cls_name]\n",
    "            \n",
    "        return evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Separate cell cause of loading time ...\n",
    "dataset = load_dataset()\n",
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vhigh', 'vhigh', '2', '2', 'small', 'low'] => ('unacc', 1.0)\n"
     ]
    }
   ],
   "source": [
    "def example_test():\n",
    "    bc = BayesClassfier()\n",
    "\n",
    "    bc.fit(dataset)\n",
    "\n",
    "    x = ['vhigh', 'vhigh', '2', '2', 'small', 'low']\n",
    "    y_pred = bc.predict(x)\n",
    "\n",
    "    print(x, '=>', y_pred)\n",
    "    \n",
    "example_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Confusion matrix ----\n",
      "[[ 56   3  22   0]\n",
      " [  5   2   0   1]\n",
      " [  4   1 236   0]\n",
      " [  9   1   0   6]]\n",
      "Accuracy: 86.71\n",
      "Precision: 70.36\n",
      "Recall: 57.39\n",
      "F1: 61.42\n"
     ]
    }
   ],
   "source": [
    "def evaluate_classifier():\n",
    "    train_ds, test_ds = train_test_split(dataset, test_size=0.2)\n",
    "    bc = BayesClassfier()\n",
    "    bc.fit(train_ds)\n",
    "    \n",
    "    y_true = test_ds['Class'].tolist()\n",
    "    y_pred = [bc.predict(x.tolist())[0] for _, x in test_ds.iterrows()]\n",
    "    \n",
    "    cnf_matrix = mtr.confusion_matrix(y_true, y_pred)\n",
    "    accuracy = mtr.accuracy_score(y_true, y_pred) * 100.0\n",
    "    precision = mtr.precision_score(y_true, y_pred, average='macro') * 100.0\n",
    "    recall = mtr.recall_score(y_true, y_pred, average='macro') * 100.0\n",
    "    f1 = mtr.f1_score(y_true, y_pred, average='macro') * 100.0\n",
    "    \n",
    "    print(\"---- Confusion matrix ----\")\n",
    "    print(cnf_matrix)\n",
    "    print('Accuracy: %.2f' % accuracy)\n",
    "    print('Precision: %.2f' % precision)\n",
    "    print('Recall: %.2f' % recall)\n",
    "    print('F1: %.2f' % f1)\n",
    "    \n",
    "    \n",
    "evaluate_classifier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
